{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import argparse\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import json, jsonlines\n",
    "import pickle\n",
    "import time\n",
    "import copy\n",
    "import transformers\n",
    "from transformers import BertTokenizer\n",
    "from knowledge_neuron.knowledge_neurons.src.custom_bert import BertForMaskedLM\n",
    "import torch.nn.functional as F\n",
    "from knowledge_neuron.knowledge_neurons.src import *\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "\n",
    "from main import *\n",
    "\n",
    "class Params:\n",
    "    def __init__(this):\n",
    "        this.temp = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* in below cell change the relation type and edit method as required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "args = Params()\n",
    "args.seed = 42\n",
    "args.output_dir = './results'\n",
    "args.output_prefix = 'TREx-all'\n",
    "args.bert_model = 'bert-base-cased'\n",
    "args.do_lower_case = False\n",
    "args.tmp_data_path = './knowledge_neuron/knowledge_neurons/data/PARAREL/data_all_allbags.json'\n",
    "args.data_path = './knowledge_neuron/knowledge_neurons/data/PARAREL/data_all.json'\n",
    "args.debug = 100000\n",
    "args.pt_relation = 'P101'\n",
    "args.max_seq_length = 128\n",
    "args.get_pred = True\n",
    "args.batch_size = 20\n",
    "args.num_batch = 1\n",
    "args.get_ig_pred = True\n",
    "args.get_ig_gold = True\n",
    "args.get_base = True\n",
    "args.phaseone_processed_data_path = './data'\n",
    "args.relative_attribution_threshold = 0.2\n",
    "#args.relations = ['P1376'] #'P463',\n",
    "args.kns_results_folder = './kns_results'\n",
    "args.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "args.n_gpu = 1\n",
    "args.model_save_path = './temp_model_save'\n",
    "args.relation_data_path = './knowledge_neuron/knowledge_neurons/data/LAMA/raw_data/TREx'\n",
    "\n",
    "# prepare eval set\n",
    "if os.path.exists(args.tmp_data_path):\n",
    "    with open(args.tmp_data_path, 'r') as f:\n",
    "        eval_bag_list_perrel = json.load(f)\n",
    "else:\n",
    "    with open(args.data_path, 'r') as f:\n",
    "        eval_bag_list_all = json.load(f)\n",
    "    # split bag list into relations\n",
    "    eval_bag_list_perrel = {}\n",
    "    for bag_idx, eval_bag in enumerate(eval_bag_list_all):\n",
    "        bag_rel = eval_bag[0][2].split('(')[0]\n",
    "        if bag_rel not in eval_bag_list_perrel:\n",
    "            eval_bag_list_perrel[bag_rel] = []\n",
    "        if len(eval_bag_list_perrel[bag_rel]) >= args.debug:\n",
    "            continue\n",
    "        eval_bag_list_perrel[bag_rel].append(eval_bag)\n",
    "    with open(args.tmp_data_path, 'w') as fw:\n",
    "        json.dump(eval_bag_list_perrel, fw, indent=2)\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-cased')\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "\n",
    "args.relations = ['P1376'] # change the relation types which you wish to edit\n",
    "args.edit_type = None\n",
    "\n",
    "model = main(model,tokenizer,eval_bag_list_perrel,args,edit_type=args.edit_type,display=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_kns_statistics(args.kns_results_folder,True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
